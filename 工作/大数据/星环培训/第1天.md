|  | 传统数据 | 大数据 |
| --- | ----: | ---: |
|  |  |  |
|  |  |  |
|  |  |  |
| 2 | 3 | 4 |

存储、计算

Flume 日志

核心 Spark Core

HDFS
容错机制

## 可能遇到场景

1. 数据倾斜：节点数据间的数量不平衡，导致节点之间的压力不平衡。
2. 数据导入可能有遇到空值定义问题

** 完整的元数据信息 **

1. 文件基本属性
2. 权限信息
3. 有哪些block构成
4. block位置信息

* 持久化信息只包含前三个 *

## 元数据的两种存储形式 ##
1. 内存元数据（NameNode）
2. 文件元数据（fsimage + edits）

** Active NameNode启动时， HDFS会进入安全模式， DataNode主动向NameNode汇报可用Block
列表等信息，在系统达到安全标准前， HDFS一直处于“只读”状态 **

#### 开发细节 ####
* 标准:四个阶段
* 简化:两个阶段(split、map)

map、reduce必须实现
shuffle有默认实现

** 总结 **
* 大数据
* hdfs
* MapReduce
* Spark
